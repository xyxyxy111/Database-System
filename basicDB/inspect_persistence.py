#!/usr/bin/env python3
"""
ç›´æ¥æ£€æŸ¥ç£ç›˜æ–‡ä»¶å†…å®¹çš„éªŒè¯è„šæœ¬
"""

import os
import sys
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from storage.storage_engine import StorageEngine


def inspect_database_file(file_path):
    """ç›´æ¥æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶çš„å†…å®¹"""
    print("=" * 60)
    print(f"ğŸ” ç›´æ¥æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶: {file_path}")
    print("=" * 60)

    if not os.path.exists(file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return

    file_size = os.path.getsize(file_path)
    print(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")

    with open(file_path, "rb") as f:
        content = f.read()

    # åˆ†ææ–‡ä»¶å¤´éƒ¨ï¼ˆå‰8å­—èŠ‚ï¼‰
    header = content[:8]
    print(f"ğŸ“‹ æ–‡ä»¶å¤´éƒ¨: {header.hex()}")

    # å°è¯•è§£æé¡µé¢æ•°é‡
    if len(header) >= 4:
        page_count = int.from_bytes(header[:4], byteorder="little")
        print(f"ğŸ“Š é¡µé¢æ•°é‡: {page_count}")

    # æ£€æŸ¥æ¯ä¸ªé¡µé¢
    page_size = 4096
    file_header_size = 8

    for page_num in range(page_count):
        page_offset = file_header_size + page_num * page_size
        if page_offset + page_size <= len(content):
            page_data = content[page_offset : page_offset + page_size]

            print(f"\nğŸ“„ é¡µé¢ {page_num}:")
            print(f"  åç§»é‡: {page_offset}")
            print(f"  é¡µé¢å¤´éƒ¨: {page_data[:32].hex()}")

            # å°è¯•æ‰¾åˆ°å¯è¯»çš„æ–‡æœ¬å†…å®¹
            text_content = ""
            for i, byte in enumerate(page_data):
                if 32 <= byte <= 126:  # å¯æ‰“å°ASCIIå­—ç¬¦
                    text_content += chr(byte)
                elif byte == 0:
                    text_content += "."
                else:
                    text_content += "?"

            # æ˜¾ç¤ºå‰200ä¸ªå­—ç¬¦
            print(f"  å†…å®¹é¢„è§ˆ: {text_content[:200]}")

            # æŸ¥æ‰¾JSONæ•°æ®ï¼ˆå…ƒæ•°æ®ï¼‰
            try:
                # å¯»æ‰¾JSONèµ·å§‹æ ‡è®°
                json_start = page_data.find(b"{")
                if json_start != -1:
                    # å¯»æ‰¾JSONç»“æŸæ ‡è®°
                    json_end = page_data.rfind(b"}")
                    if json_end != -1 and json_end > json_start:
                        json_data = page_data[json_start : json_end + 1].decode(
                            "utf-8", errors="ignore"
                        )
                        try:
                            parsed_json = json.loads(json_data)
                            print(
                                f"  ğŸ“Š è§£æçš„å…ƒæ•°æ®: {json.dumps(parsed_json, indent=2, ensure_ascii=False)}"
                            )
                        except json.JSONDecodeError:
                            print(f"  ğŸ“„ åŸå§‹JSONæ•°æ®: {json_data[:100]}...")
            except Exception as e:
                print(f"  âš ï¸  JSONè§£æå¤±è´¥: {e}")

            # æŸ¥æ‰¾è®°å½•æ•°æ®æ¨¡å¼
            record_patterns = []
            i = 32  # è·³è¿‡é¡µé¢å¤´éƒ¨
            while i < len(page_data) - 4:
                # æŸ¥æ‰¾å¯èƒ½çš„è®°å½•é•¿åº¦æ ‡è®°
                record_len = int.from_bytes(page_data[i : i + 4], byteorder="little")
                if 10 <= record_len <= 200:  # åˆç†çš„è®°å½•é•¿åº¦
                    record_data = page_data[i + 4 : i + 4 + record_len]
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«å¯è¯»å­—ç¬¦
                    readable_chars = sum(1 for b in record_data if 32 <= b <= 126)
                    if readable_chars > len(record_data) * 0.3:  # è‡³å°‘30%å¯è¯»å­—ç¬¦
                        readable_text = "".join(
                            chr(b) if 32 <= b <= 126 else "." for b in record_data
                        )
                        record_patterns.append(
                            f"è®°å½•@{i}: é•¿åº¦={record_len}, å†…å®¹='{readable_text[:50]}'"
                        )
                        i += 4 + record_len
                    else:
                        i += 1
                else:
                    i += 1

            if record_patterns:
                print(f"  ğŸ“ å¯èƒ½çš„è®°å½•:")
                for pattern in record_patterns[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"    {pattern}")


def cross_verify_persistence():
    """äº¤å‰éªŒè¯æŒä¹…åŒ–åŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("ğŸ”„ äº¤å‰éªŒè¯æŒä¹…åŒ–åŠŸèƒ½")
    print("=" * 60)

    test_file = "cross_verify.db"

    # æ¸…ç†æ—§æ–‡ä»¶
    if os.path.exists(test_file):
        os.remove(test_file)

    print("ç¬¬1è½®ï¼šå†™å…¥æ•°æ®")
    print("-" * 30)

    # ç¬¬ä¸€æ¬¡å†™å…¥
    storage1 = StorageEngine(test_file)
    storage1.create_table(
        "users", ["id", "username", "email"], ["INT", "VARCHAR", "VARCHAR"]
    )

    users_data = [
        [1, "admin", "admin@example.com"],
        [2, "user1", "user1@example.com"],
        [3, "test", "test@example.com"],
    ]

    for user in users_data:
        storage1.insert_record("users", user)
        print(f"  å†™å…¥: {user}")

    storage1.flush()
    storage1.close()

    print(f"  æ–‡ä»¶å¤§å°: {os.path.getsize(test_file)} å­—èŠ‚")

    # æ£€æŸ¥æ–‡ä»¶å†…å®¹
    inspect_database_file(test_file)

    print("\nç¬¬2è½®ï¼šç¨‹åºé‡å¯åè¯»å–")
    print("-" * 30)

    # æ¨¡æ‹Ÿç¨‹åºé‡å¯
    storage2 = StorageEngine(test_file)
    recovered_users = storage2.scan_table("users")

    print(f"  æ¢å¤çš„è®°å½•æ•°: {len(recovered_users)}")
    for user in recovered_users:
        print(f"  æ¢å¤: {user.values}")

    # éªŒè¯æ•°æ®ä¸€è‡´æ€§
    original = [user for user in users_data]
    recovered = [user.values for user in recovered_users]

    print(f"  æ•°æ®ä¸€è‡´æ€§: {'âœ… é€šè¿‡' if original == recovered else 'âŒ å¤±è´¥'}")

    storage2.close()

    print("\nç¬¬3è½®ï¼šè¿½åŠ æ›´å¤šæ•°æ®")
    print("-" * 30)

    # è¿½åŠ æ•°æ®
    storage3 = StorageEngine(test_file)
    new_users = [[4, "newuser", "new@example.com"], [5, "guest", "guest@example.com"]]

    for user in new_users:
        storage3.insert_record("users", user)
        print(f"  è¿½åŠ : {user}")

    storage3.flush()
    storage3.close()

    print(f"  æ–‡ä»¶å¤§å°: {os.path.getsize(test_file)} å­—èŠ‚")

    print("\nç¬¬4è½®ï¼šæœ€ç»ˆéªŒè¯")
    print("-" * 30)

    # æœ€ç»ˆéªŒè¯
    storage4 = StorageEngine(test_file)
    final_users = storage4.scan_table("users")

    print(f"  æœ€ç»ˆè®°å½•æ•°: {len(final_users)}")
    expected_total = len(users_data) + len(new_users)
    print(f"  æœŸæœ›è®°å½•æ•°: {expected_total}")
    print(
        f"  éªŒè¯ç»“æœ: {'âœ… é€šè¿‡' if len(final_users) == expected_total else 'âŒ å¤±è´¥'}"
    )

    print("  æ‰€æœ‰è®°å½•:")
    for i, user in enumerate(final_users, 1):
        print(f"    {i}. {user.values}")

    storage4.close()

    # æœ€ç»ˆæ–‡ä»¶æ£€æŸ¥
    print("\næœ€ç»ˆæ–‡ä»¶å†…å®¹æ£€æŸ¥:")
    inspect_database_file(test_file)


if __name__ == "__main__":
    # æ£€æŸ¥ç°æœ‰çš„æ¼”ç¤ºæ–‡ä»¶
    demo_files = ["minidb_demo.db", "persistence_test.db"]

    for file_name in demo_files:
        if os.path.exists(file_name):
            inspect_database_file(file_name)
            print("\n")

    # è¿›è¡Œäº¤å‰éªŒè¯
    cross_verify_persistence()
